{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "node_edge_detection.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNxgQHBR9aAPpQiUrm14b/f",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/meti-94/BERT-QA/blob/main/node_edge_detection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DQ-LV62ByxcR",
        "outputId": "f22e5a0a-0800-4881-f82c-c6e643c9177d"
      },
      "source": [
        "!pip install transformers\r\n",
        "!pip uninstall -y tensorflow\r\n",
        "!pip install fuzzywuzzy[speedup]\r\n",
        "!pip install networkx"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.6/dist-packages (4.2.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: tokenizers==0.9.4 in /usr/local/lib/python3.6/dist-packages (from transformers) (0.9.4)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.19.5)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers) (20.8)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.6/dist-packages (from transformers) (0.0.43)\n",
            "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.8)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.41.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from transformers) (3.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.0.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.12.5)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.7.4.3)\n",
            "\u001b[33mWARNING: Skipping tensorflow as it is not installed.\u001b[0m\n",
            "Collecting fuzzywuzzy[speedup]\n",
            "  Downloading https://files.pythonhosted.org/packages/43/ff/74f23998ad2f93b945c0309f825be92e04e0348e062026998b5eefef4c33/fuzzywuzzy-0.18.0-py2.py3-none-any.whl\n",
            "Collecting python-levenshtein>=0.12; extra == \"speedup\"\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/6b/ca/1a9d7115f233d929d4f25a4021795cd97cc89eeb82723ea98dd44390a530/python-Levenshtein-0.12.1.tar.gz (50kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 3.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from python-levenshtein>=0.12; extra == \"speedup\"->fuzzywuzzy[speedup]) (51.3.3)\n",
            "Building wheels for collected packages: python-levenshtein\n",
            "  Building wheel for python-levenshtein (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for python-levenshtein: filename=python_Levenshtein-0.12.1-cp36-cp36m-linux_x86_64.whl size=149167 sha256=6038111654425f1c9e8b2f76f033d8be3df09ab87d2b0cad50edc6fac309a11e\n",
            "  Stored in directory: /root/.cache/pip/wheels/ae/69/ea/4798f98317cbab35d78fea64d36bd7b2b18faca88568ef15b0\n",
            "Successfully built python-levenshtein\n",
            "Installing collected packages: python-levenshtein, fuzzywuzzy\n",
            "Successfully installed fuzzywuzzy-0.18.0 python-levenshtein-0.12.1\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.6/dist-packages (2.5)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.6/dist-packages (from networkx) (4.4.2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lK5AY1cWmoqG",
        "outputId": "548efc41-1315-4680-ea0e-5f74a32fbb37"
      },
      "source": [
        "!git clone https://github.com/meti-94/BERT-QA.git"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'BERT-QA'...\n",
            "remote: Enumerating objects: 204, done.\u001b[K\n",
            "remote: Counting objects: 100% (204/204), done.\u001b[K\n",
            "remote: Compressing objects: 100% (156/156), done.\u001b[K\n",
            "remote: Total 204 (delta 62), reused 169 (delta 33), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (204/204), 30.26 MiB | 18.45 MiB/s, done.\n",
            "Resolving deltas: 100% (62/62), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2-eIIezrzF9g",
        "outputId": "873b9ff1-97ac-499b-c35e-636179b7f724"
      },
      "source": [
        "%cd /content/BERT-QA/\r\n",
        "!python node_edge_bert.py"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/BERT-QA\n",
            "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): huggingface.co:443\n",
            "DEBUG:urllib3.connectionpool:https://huggingface.co:443 \"HEAD /bert-base-uncased/resolve/main/config.json HTTP/1.1\" 200 0\n",
            "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): huggingface.co:443\n",
            "DEBUG:urllib3.connectionpool:https://huggingface.co:443 \"HEAD /bert-base-uncased/resolve/main/pytorch_model.bin HTTP/1.1\" 302 0\n",
            "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): huggingface.co:443\n",
            "DEBUG:urllib3.connectionpool:https://huggingface.co:443 \"HEAD /bert-base-uncased/resolve/main/vocab.txt HTTP/1.1\" 200 0\n",
            "Train Epoch Number 1: 100% 58/58 [00:35<00:00,  1.63it/s]\n",
            "INFO:root:Epoch number: 1 Train Loss is equal: 247.8325958251953\n",
            "Eval Epoch Number 1: 100% 11/11 [00:02<00:00,  5.45it/s]\n",
            "INFO:root:Epoch number: 1 Eval Loss is equal: 20.340179443359375\n",
            "Train Epoch Number 2: 100% 58/58 [00:36<00:00,  1.60it/s]\n",
            "INFO:root:Epoch number: 2 Train Loss is equal: 22.968164443969727\n",
            "Eval Epoch Number 2: 100% 11/11 [00:02<00:00,  5.32it/s]\n",
            "INFO:root:Epoch number: 2 Eval Loss is equal: 14.562334060668945\n",
            "Train Epoch Number 3: 100% 58/58 [00:36<00:00,  1.57it/s]\n",
            "INFO:root:Epoch number: 3 Train Loss is equal: 15.005765914916992\n",
            "Eval Epoch Number 3: 100% 11/11 [00:02<00:00,  5.22it/s]\n",
            "INFO:root:Epoch number: 3 Eval Loss is equal: 16.69527244567871\n",
            "Train Epoch Number 4: 100% 58/58 [00:37<00:00,  1.54it/s]\n",
            "INFO:root:Epoch number: 4 Train Loss is equal: 12.456369400024414\n",
            "Eval Epoch Number 4: 100% 11/11 [00:02<00:00,  5.13it/s]\n",
            "INFO:root:Epoch number: 4 Eval Loss is equal: 12.881731986999512\n",
            "Train Epoch Number 5: 100% 58/58 [00:37<00:00,  1.54it/s]\n",
            "INFO:root:Epoch number: 5 Train Loss is equal: 11.208187103271484\n",
            "Eval Epoch Number 5: 100% 11/11 [00:02<00:00,  5.18it/s]\n",
            "INFO:root:Epoch number: 5 Eval Loss is equal: 12.478543281555176\n",
            "Train Epoch Number 6: 100% 58/58 [00:37<00:00,  1.55it/s]\n",
            "INFO:root:Epoch number: 6 Train Loss is equal: 9.395092010498047\n",
            "Eval Epoch Number 6: 100% 11/11 [00:02<00:00,  5.18it/s]\n",
            "INFO:root:Epoch number: 6 Eval Loss is equal: 11.649856567382812\n",
            "Predicting ...: 100% 59/59 [00:06<00:00,  9.76it/s]\n",
            "INFO:root:Dataset-wide F1, precision and recall:\n",
            "INFO:root:0.9891908585546633, 0.9915641204241158, 0.9868289301394131\n",
            "INFO:root:Averaged F1, precision and recall:\n",
            "INFO:root:nan, 0.9886706689536878, 0.9870528056848811\n",
            "INFO:root:Span accuracy\n",
            "INFO:root:0.986106346483705\n",
            "INFO:root:Averaged F1, precision and recall:\n",
            "INFO:root:0.9936785801118406, 0.9954938497137986, 0.991869918699187\n",
            "INFO:root:Span accuracy\n",
            "INFO:root:0.9792452830188679\n",
            "Question                    Node               Edge\n",
            "--------------------------  -----------------  --------------------\n",
            "Where was Bill Gates Born?  ['bill', 'gates']  ['was', 'born', '?']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S6h_BRN-zs6k",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6d4d288a-b1fc-4044-d56f-5a58e814b2e4"
      },
      "source": [
        "!python main.py > result.txt"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): huggingface.co:443\n",
            "DEBUG:urllib3.connectionpool:https://huggingface.co:443 \"HEAD /bert-base-uncased/resolve/main/config.json HTTP/1.1\" 200 0\n",
            "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): huggingface.co:443\n",
            "DEBUG:urllib3.connectionpool:https://huggingface.co:443 \"HEAD /bert-base-uncased/resolve/main/pytorch_model.bin HTTP/1.1\" 302 0\n",
            "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): huggingface.co:443\n",
            "DEBUG:urllib3.connectionpool:https://huggingface.co:443 \"HEAD /bert-base-uncased/resolve/main/vocab.txt HTTP/1.1\" 200 0\n",
            "INFO:numexpr.utils:NumExpr defaulting to 2 threads.\n",
            "Indexing ...: 100% 407236/407236 [00:43<00:00, 9342.52it/s]\n",
            "100% 5830/5830 [1:00:16<00:00,  1.61it/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ws4lrw2mnf8b"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}